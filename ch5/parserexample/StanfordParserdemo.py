from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from pycorenlp import StanfordCoreNLP
from nltk.tree import Tree
from nltk.parse.stanford import StanfordDependencyParser

nlp = StanfordCoreNLP('http://localhost:9000')
def stanfordparserdemo(sentnece):
    text = (sentnece)

    output = nlp.annotate(text, properties={
        'annotators': 'tokenize,ssplit,pos,depparse,parse',
        'outputFormat': 'json'
    })

    print ("\n------------Stanford Parser Parseing Result------------")
    parsetree = output['sentences'][0]['parse']
    print("\n------parsing------\n")
    print(parsetree)
    print ("\n------ Words inside NP ------\n")
    for i in Tree.fromstring(parsetree).subtrees():
        if i.label() == 'NP':
            print(i.leaves(), i.label())
    print ("\n------ Words inside NP with POS tags ------\n")
    for i in Tree.fromstring(parsetree).subtrees():
        if i.label() == 'NP':
            print(i)

def NLTKparserfordependancies(sentnece):

    path_to_jar = '/home/jalaj/stanford-corenlp-full-2016-10-31/stanford-corenlp-3.7.0.jar'
    path_to_models_jar = '/home/jalaj/stanford-corenlp-full-2016-10-31/stanford-corenlp-3.7.0-models.jar'
    dependency_parser = StanfordDependencyParser(path_to_jar=path_to_jar, path_to_models_jar=path_to_models_jar)
    result = dependency_parser.raw_parse(sentnece)
    dep = next(result)
    print("\n------Dependencies------\n")
    print(list(dep.triples()))

if __name__ == "__main__":
    stanfordparserdemo('The boy put tortoise on the rug.')
    NLTKparserfordependancies('The boy put tortoise on the rug.')
